apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "llama2"
  namespace: my-profile
  annotations:
    "sidecar.istio.io/inject": "false"
spec:
  predictor:
    containers:
      - image: ghcr.io/civo-learn/llama2-kf-oai:latest
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: "8"
            memory: "32Gi"
          requests:
            cpu: "8"
            memory: "32Gi"
